{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad function started\n",
      "grad function completed\n",
      "(25, 401) (401, 3)\n",
      "appended z (25, 3)\n",
      "appended a (25, 3)\n",
      "(10, 26) (26, 3)\n",
      "appended z (10, 3)\n",
      "appended a (10, 3)\n",
      "cost function completed\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-50b639052711>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[1;31m# );\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m \u001b[0mJ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuildModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[1;31m# nn_params = [];\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[1;31m# for theta in J.Thetas:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-50b639052711>\u001b[0m in \u001b[0;36mbuildModel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m                             \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                             \u001b[0mfull_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                             \u001b[0mretall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m                         );\n\u001b[1;32m    238\u001b[0m         \u001b[0mopTheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfminOutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mfmin_bfgs\u001b[0;34m(f, x0, fprime, args, gtol, norm, epsilon, maxiter, full_output, disp, retall, callback)\u001b[0m\n\u001b[1;32m    857\u001b[0m             'return_all': retall}\n\u001b[1;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[1;31m# Sets the initial step guess to dx ~ 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0mold_fval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m     \u001b[0mold_old_fval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_fval\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgfk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0mxk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2127\u001b[0m                 \u001b[0msqnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2129\u001b[0;31m                 \u001b[0msqnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2130\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "import os;\n",
    "\n",
    "import sys;\n",
    "sys.path.insert(0,os.getcwd() + '\\\\..\\\\lib');\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as spio;\n",
    "from random import randint;\n",
    "import matplotlib.pyplot as plot\n",
    "from scipy.optimize import fmin_bfgs;\n",
    "\n",
    "def displayImage(X):\n",
    "    \n",
    "    # fname = 'image.png'\n",
    "    # image = Image.open(fname).convert(\"L\")\n",
    "    # arr = np.asarray(image)\n",
    "\n",
    "    plot.imshow(X, cmap='gray')\n",
    "    plot.show()\n",
    "\n",
    "# displayImage(np.reshape(X[0],(20,20)));\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, X, y, lam, yClasses, hiddenLayerSizes):\n",
    "        \n",
    "        self.X = X;\n",
    "        self.lam = lam;\n",
    "        self.m = X.shape[0];\n",
    "        self.n = X.shape[1];\n",
    "        self.a = [];    #declaring here since grad function throws error, not sure in what order grad and cost functions are executed\n",
    "        \n",
    "        y1 = np.zeros((self.m, yClasses));\n",
    "#         print(\n",
    "        \n",
    "#             y1.shape,\n",
    "#             y,\n",
    "#             y[0]%10\n",
    "            \n",
    "#         );\n",
    "        \n",
    "#         try:\n",
    "        for i in range(0,self.m):\n",
    "#             print(i, (y[i] % 10));\n",
    "            y1[i, (y[i] % 10)] = 1;\n",
    "        self.y = y1;\n",
    "#         except:\n",
    "#             print(i);\n",
    "        \n",
    "        \n",
    "        \n",
    "#         self.X = NeuralNetwork.addIntercept(self.X);\n",
    "#         print(\n",
    "#             [self.n],\n",
    "#             hiddenLayerSizes,\n",
    "#             [yClasses]\n",
    "#         );\n",
    "        thetasDimensions = [self.n] + hiddenLayerSizes + [yClasses];\n",
    "#         print(\n",
    "#             thetasDimensions\n",
    "#         );\n",
    "        self.Thetas = [];\n",
    "        self.nn_params  = [];\n",
    "        for i in range(0, len(thetasDimensions)-1):\n",
    "            theta = self.initializeRandomWeights(thetasDimensions[i], thetasDimensions[i+1]);\n",
    "            self.Thetas.append(theta);\n",
    "            if len(self.nn_params) == 0:\n",
    "                self.nn_params = theta.flatten();\n",
    "            self.nn_params = np.hstack([self.nn_params, theta.flatten()]);\n",
    "                \n",
    "#         print(\n",
    "#             self.Thetas\n",
    "#         );\n",
    "\n",
    "    @staticmethod\n",
    "    def addIntercept(X):\n",
    "        m = X.shape[0];\n",
    "        X = np.hstack((np.ones((m,1)), X));\n",
    "        return X;       \n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-1 * z));\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoidGradient(z):\n",
    "        return np.multiply(LR.sigmoid(z), np.subtract( 1, LR.sigmoid(z)));\n",
    "    \n",
    "    @staticmethod\n",
    "    def initializeRandomWeights(lIn, lOut):\n",
    "        epsilonInit = 0.12;\n",
    "        w = np.zeros((lOut, lIn + 1));\n",
    "        w = np.random.rand(lOut, lIn + 1);\n",
    "        w = np.subtract( np.multiply( w, (2.0 * epsilonInit) ), epsilonInit );\n",
    "        return w;\n",
    "    \n",
    "    def costFunction(self, nn_params):\n",
    "\n",
    "        m = self.X.shape[0];\n",
    "        \n",
    "        \n",
    "        a = np.transpose(self.X);\n",
    "        self.z = [];\n",
    "        regularizationSum = 0;\n",
    "        \n",
    "#         a1 = np.transpose(LR.addIntercept(X));\n",
    "#         z2 = np.dot(theta1, a1);\n",
    "#         a2 = LR.sigmoid(z2);\n",
    "#         a2 = np.transpose(LR.addIntercept(np.transpose(a2)));\n",
    "#         z3 = np.dot(theta2, a2);\n",
    "#         a3 = LR.sigmoid(z3);\n",
    "\n",
    "        startIndex = 0;\n",
    "        for i in range(0, len(self.Thetas)):\n",
    "            endIndex = startIndex + (self.Thetas[i].shape[0] * self.Thetas[i].shape[1]);\n",
    "            self.Thetas[i] = np.reshape(nn_params[startIndex:endIndex], self.Thetas[i].shape);\n",
    "            startIndex = endIndex;\n",
    "            \n",
    "            print(self.Thetas[i].shape, np.transpose(NeuralNetwork.addIntercept(np.transpose(a))).shape);\n",
    "            z = np.dot(self.Thetas[i], np.transpose(NeuralNetwork.addIntercept(np.transpose(a))));\n",
    "            print(\"appended z\", z.shape);\n",
    "            self.z.append(z);\n",
    "            a = NeuralNetwork.sigmoid(z);\n",
    "            print(\"appended a\", a.shape);\n",
    "            self.a.append(a);\n",
    "      \n",
    "            regularizationSum += np.sum(\n",
    "                    np.square(\n",
    "                        np.hstack( [np.zeros((self.Thetas[i].shape[0],1)), self.Thetas[i][:, 1:]] )\n",
    "                    )\n",
    "            );\n",
    "        \n",
    "        a = np.transpose(a);\n",
    "        J = np.add(\n",
    "                np.multiply(\n",
    "                    (1/self.m) \n",
    "                    , np.sum( \n",
    "                            np.subtract(\n",
    "                                np.multiply(\n",
    "                                    np.multiply(-1, self.y),\n",
    "                                    np.log(a)\n",
    "                                )\n",
    "                                , np.multiply(\n",
    "              \n",
    "                                    np.subtract(1, self.y), \n",
    "                                    np.log(np.subtract(1, a))\n",
    "                                )\n",
    "                            )\n",
    "                        )\n",
    "                   )  \n",
    "                , (\n",
    "                    (self.lam/(2 * self.m))  \n",
    "                    * regularizationSum\n",
    "                )\n",
    "        );\n",
    "        print(\"cost function completed\");\n",
    "        return J;\n",
    "                                                  \n",
    "    def gradFunction(self, nn_params):\n",
    "                                                  \n",
    "#         Thetas = [i];\n",
    "        \n",
    "#         startIndex = 0;\n",
    "#         for i in range(0, len(self.Thetas)):\n",
    "#             endIndex = startIndex + (self.Thetas[i].shape[0] * self.Thetas[i].shape[1]);\n",
    "#             Thetas[i] = np.reshape(nn_params[startIndex:endIndex], self.Thetas[i].shape);\n",
    "#             startIndex = endIndex;\n",
    "#         print(\"a from gradFunction\", self.a);\n",
    "        print(\"grad function started\");\n",
    "        if len(self.a) == 0:\n",
    "            print(\"grad function completed\");\n",
    "            return;\n",
    "#         delta3 = np.subtract(a3, np.transpose(y1));\n",
    "        print(\"just entering the function\");\n",
    "        print(\n",
    "            \"a\", type(self.a.shape),\n",
    "            \"y\", type(self.y.shape),\n",
    "            \"Thetas\", type(self.Thetas.shape)\n",
    "            \n",
    "        );\n",
    "            \n",
    "        self.Deltas = [];\n",
    "        currDelta = np.subtract(self.a[-1], np.transpose(self.y));\n",
    "        self.Deltas.append( currDelta );\n",
    "        \n",
    "#         delta2 = np.multiply( np.dot(np.transpose(theta2), delta3)[1:, :], sigmoidGradient(z2));\n",
    "        for i in reversed(range(1, len(self.a)-1)):\n",
    "            currDelta = np.multiply( np.dot(np.transpose(self.Thetas[i]), currDelta)[1:, :], sigmoidGradient(self.z[1]) );\n",
    "            self.Deltas.append(currDelta);\n",
    "        \n",
    "        self.Deltas = list(reversed(self.Deltas));\n",
    "#         theta1Grad = np.zeros(theta1Shape);\n",
    "#         theta2Grad = np.zeros(theta2Shape);\n",
    "#         theta1Grad = theta1Grad + np.dot(delta2, np.transpose(a1));\n",
    "#         theta2Grad = theta2Grad + np.dot(delta3, np.transpose(a2));\n",
    "#         theta1Grad = np.divide(theta1Grad, m) + np.hstack( [np.zeros((theta1.shape[0],1)), np.multiply((lam/m), theta1[:, 1:])] );\n",
    "#         theta2Grad = np.divide(theta2Grad, m) + np.hstack( [np.zeros((theta2.shape[0],1)), np.multiply((lam/m), theta2[:, 1:])] );\n",
    "        self.ThetasGrad = [];\n",
    "        for i in range(0, len(self.Thetas)):\n",
    "#             self.ThetasGrad.append(np.zeros(self.Thetas[i].shape));\n",
    "            thetaGrad = np.dot(self.Deltas[i], np.transpose(self.a[i]));\n",
    "            thetaGrad = np.divide(\n",
    "                thetaGrad\n",
    "                , self.m\n",
    "            ) \n",
    "            + np.hstack(\n",
    "                [np.zeros((thetaGrad.shape[0],1))\n",
    "                 , np.multiply(\n",
    "                     (self.lam/self.m)\n",
    "                     , thetaGrad[:, 1:]\n",
    "                 )\n",
    "                ] \n",
    "            );\n",
    "            self.ThetasGrad.append(thetaGrad);\n",
    "        \n",
    "        nn_params = [];\n",
    "        for theta in self.ThetasGrad:\n",
    "            if len(nn_params)==0:\n",
    "                nn_params = theta.flatten();\n",
    "                continue;\n",
    "            nn_params = np.hstack([nn_params, theta.flatten()]);\n",
    "        \n",
    "        print(\"grad function completed\");\n",
    "        \n",
    "        return nn_params;\n",
    "         \n",
    "    def buildModel(self):\n",
    "        \n",
    "        fminOutput = fmin_bfgs(\n",
    "                            self.costFunction,\n",
    "                            self.nn_params,\n",
    "                            self.gradFunction,\n",
    "                            disp=True,\n",
    "                            maxiter=400,\n",
    "                            full_output = True,\n",
    "                            retall=True\n",
    "                        );\n",
    "        opTheta = fminOutput[0];\n",
    "        return opTheta;\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "data1 = spio.loadmat(\"C:/Dinesh/Projects/Learning/machinelearning_coursera/ex4/ex4data1.mat\");\n",
    "X = data1[\"X\"];\n",
    "y = data1[\"y\"];\n",
    "\n",
    "# data1 = spio.loadmat(\"C:/Dinesh/Projects/Learning/machinelearning_coursera/ex4/ex4weights.mat\");\n",
    "# theta1 = data1[\"Theta1\"];\n",
    "# theta2 = data1[\"Theta2\"];\n",
    "\n",
    "# theta1 = initializeRandomWeights(n, hiddenLayerSize);\n",
    "# theta2 = initializeRandomWeights(hiddenLayerSize, yClasses)\n",
    "\n",
    "# nn_params = np.hstack([theta1.flatten(), theta2.flatten()])\n",
    "# print(\n",
    "#     theta1.shape,\n",
    "#     theta2.shape,\n",
    "#     nn_params.shape\n",
    "    \n",
    "# )\n",
    "\n",
    "# m = X.shape[0];\n",
    "# n = X.shape[1];\n",
    "# hiddenLayerSize = 25;\n",
    "# yClasses = 10;\n",
    "# lam = 0;\n",
    "\n",
    "# J = costFunction(nn_params, n, hiddenLayerSize, yClasses, X, y, lam);\n",
    "\n",
    "\n",
    "# print(\n",
    "\n",
    "#     X[1,:].shape, y[1].shape\n",
    "\n",
    "# );\n",
    "J = NeuralNetwork(X[1:4,:], y[1:4], 0.1, 10, [25]).buildModel();\n",
    "# nn_params = [];\n",
    "# for theta in J.Thetas:\n",
    "#     if len(nn_params)==0:\n",
    "#         nn_params = theta.flatten();\n",
    "#         continue;\n",
    "#     nn_params = np.hstack([nn_params, theta.flatten()]);\n",
    "# cost = J.costFunction(nn_params);\n",
    "# print(\"cost\", cost);\n",
    "print(\"cost\", J);\n",
    "print(\"program execution done\");\n",
    "# print(prev.shape)\n",
    "                     \n",
    "\n",
    "# fminOutput = fmin_bfgs(\n",
    "#                             costFunction,\n",
    "#                             nn_params,\n",
    "#                             gradFunction,\n",
    "#                             disp=True,\n",
    "#                             maxiter=400,\n",
    "#                             full_output = True,\n",
    "#                             retall=True\n",
    "#                         );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = [1,2,3];\n",
    "test = list(reversed(test));\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
